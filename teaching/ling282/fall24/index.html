<!DOCTYPE html>
<html lang="en">

<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">

	<title>UR LING 282/482 (Fall 2024)</title>

	<!-- Bootstrap core CSS -->
	<link href="../vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">

	<!-- Custom styles for this template -->
	<link href="../css/scrolling-nav.css" rel="stylesheet">
</head>

<body id="page-top">
	<!-- Navigation -->
	<nav class="navbar navbar-expand-lg navbar-dark bg-dark fixed-top" id="mainNav">
		<div class="container">
			<a class="navbar-brand js-scroll-trigger" href="#page-top">LING 282: Deep Learning Methods in Computational Linguistics [Fall '24]</a>
			<button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
				<span class="navbar-toggler-icon"></span>
			</button>
			<div class="collapse navbar-collapse" id="navbarResponsive">
				<ul class="navbar-nav ml-auto">
					<li class="nav-item">
						<a class="nav-link js-scroll-trigger" href="#information">Information</a>
					</li>
					<li class="nav-item">
						<a class="nav-link js-scroll-trigger" href="#policies">Policies</a>
					</li>
					<li class="nav-item">
						<a class="nav-link js-scroll-trigger" href="#schedule">Schedule</a>
					</li>
				</ul>
			</div>
		</div>
	</nav>

	<section id="information">
		<div class="container">
			<div class="row">
				<div class="col-lg-12 mx-auto">
					<h2>Course Description</h2>
					<p class="lead">
						The application of neural network methods - under the name <em>Deep Learning</em> - has led to breakthroughs in a wide range of
						fields, including in building language technologies (e.g. for search, translation, text input prediction). This course
						will provide a hands-on introduction to the use of deep learning methods for processing natural language. Methods to be
						covered include static word embeddings, feed-forward networks for text, recurrent neural networks, transformers,
						pre-training and transfer learning, with applications including sentiment analysis, translation, and generation.
					</p>

					<table class="table">
						<thead>
							<tr>
							<th>Days</th>
							<th>Time</th>
							<th>Location</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td>Monday and Wednesday</td>
								<td>10:25 - 11:40 AM</td>
								<td><a href="https://www.rochester.edu/college/ecm/locations/hylan.html" target="_blank">Hylan</a> 307</td>
							</tr>
						</tbody>
					</table>

					<h2 class="pt-2">Teaching Staff</h2>
					<table class="table">
						<thead>
							<tr>
								<th>Role</th>
								<th>Name</th>
								<th>Office</th>
								<th>Office Hours</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td>Instructor</td>
								<td><a href="https://cmdowney88.github.io" target="_blank">C.M. Downey</a></td>
								<td>Lattimore 507</td>
								<td>TBA</td>
							</tr>
						</tbody>
					</table>

					<h2 class="pt-2">Recommended Textbooks</h2>

					<p>While relevant readings are posted in the schedule below, the following are very good general resources.  Names that are used to refer to these works are included in parentheses.</p>
					<ul>
						<li>[JM] Jurafsky and Martin, <em><a href="https://web.stanford.edu/~jurafsky/slp3/" target="_blank">Speech and Language Processing (3rd ed)</a></em></li>
						<li>[YG] Yoav Goldberg, <em><a href="https://rochester.primo.exlibrisgroup.com/permalink/01ROCH_INST/1vg5sr1/alma9978538523405216" target="_blank">Neural Network Methods in Natural Language Processing</a></em> (digital access through UR librairies)</li>
						<li>[GBC] Goodfellow, Bengio, and Courville, <em><a href="https://www.deeplearningbook.org/" target="_blank">Deep Learning</a></em></li>
					</ul>


					<h2 class="pt-2">Prerequisites</h2>
					<ul>
						<li>Programming in Python</li>
						<li>Linux/Unix commands</li>
						<li>Calculus 1</li>
						<li>Knowledge of vectors and matrices</li>
					</ul>

					<h2 class="pt-2">Course Resources</h2>

					<ul>
						<li>More information coming soon</li>
					</ul>
				</div>
			</div>
		</div>
	</section>

	<section id="policies" class="bg-light">
		<div class="container">
			<div class="row">
				<div class="col-lg-12 mx-auto">
					<h1>Policies</h1>
					<p>As we continue to navigate health crises and troubling world events, stress and anxiety are at all-time highs.  If you find yourself struggling with a difficult concept; stressed over politics or health; or annoyed at a classmate, please remember that they feel similar. Maybe not in your very moment, but certainly recently or soon. Some of you may find remote learning particularly conducive to your style of learning and personality. Others will find it difficult to concentrate and maintain enthusiasm.  These are all normal reactions.</p>

					<p>If you find yourself having trouble learning in class, please do not hesitate to let one of us know.  Our goal is to make this class a bright spot in these unprecedented times, and to do whatever we can to promote a healthy learning environment for all.</p>

					<h2 class="pt-2">A note on time zones</h2>
					<p>All deadlines and meeting times for this class are in "Eastern Time". <strong>Please note:</strong> on Sunday November 3, this will change from Eastern Daylight Time (EDT/UTC-4) to Eastern Standard Time (EST/UTC-5).</p>

					<h2 class="pt-2">Grading</h2>
					<ul>
						<li>100%: Homework Assignments</li>
					</ul>
				</div>
			</div>
		</div>
	</section>

	<section id="schedule">
		<div class="container">
			<div class="row">
				<div class="col-lg-12 mx-auto">

					<h2>Schedule</h2>

					<br />

					<table class="table">
						<thead>
							<tr>
								<th width="10%">Date</th>
								<th>Topics + Slides</th>
								<th>Readings</th>
								<th width="15%">Events</th>
							</tr>
						</thead>
						<tbody>
							<tr>
								<td>Aug 26</td>
								<td>
									Introduction / Overview; History
								</td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td>Aug 28</td>
								<td>
									Linear Algebra
								</td>
								<td>
									<a href="https://youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab" target="_blank">Essence of Linear Algebra Ch.1-8</a>
								</td>
								<td></td>
							</tr>
							<tr>
								<td>Sep 2</td>
								<td colspan="3" align="center">Labor Day: No Class</td>
							</tr>
							<tr>
								<td>Sep 4</td>
								<td>
									Word vectors; Gradient descent
								</td>
								<td>
									JM <a href="https://web.stanford.edu/~jurafsky/slp3/5.pdf" target="_blank">5.4-5.6</a>, <a href="https://web.stanford.edu/~jurafsky/slp3/6.pdf" target="_blank">6</a>
									<br />
									YG 2
								</td>
								<td></td>
							</tr>
							<tr>
								<td>Sep 9</td>
								<td>
									Word2Vec
								</td>
								<td>
									JM <a href="https://web.stanford.edu/~jurafsky/slp3/6.pdf" target="_blank">6.8 - 6.12</a>
								</td>
								<td></td>
							</tr>
							<tr>
								<td>Sep 11</td>
								<td>
									Neural Networks
									<br />
									edugrad library
								</td>
								<td>
									JM <a href="https://web.stanford.edu/~jurafsky/slp3/7.pdf" target="_blank">7.1 - 7.4</a>
									<br />
									YG 4
								</td>
								<td></td>
							</tr>
							<tr>
								<td>Sep 16</td>
								<td>
									Computation graphs; Backpropagation
								</td>
								<td>
									JM <a href="https://web.stanford.edu/~jurafsky/slp3/7.pdf" target="_blank">7.6.3 - 7.6.5</a>
									<br />
									YG 5.1.1 - 5.1.2
									<br />
									GBC <a href="https://www.deeplearningbook.org/contents/mlp.html" target="_blank">6.5</a>
									<br /><br />
									<a href="https://colah.github.io/posts/2015-08-Backprop/" target="_blank">Calculus on computational graphs</a>
									<br />
									<a href="http://cs231n.github.io/optimization-2/" target="_blank">CS 231n notes 1</a>
									<br />
									<a href="http://cs231n.stanford.edu/vecDerivs.pdf" target="_blank">CS 231n notes 2 (vector/tensor derivatives)</a>
									<br />
									<a href="https://medium.com/@karpathy/yes-you-should-understand-backprop-e2f06eab496b" target="_blank">Yes, you should understand backprop</a>
								</td>
								<td></td>
							</tr>
							<tr>
								<td>Sep 18</td>
								<td>
									Feed-forward networks for LM and classification
								</td>
								<td>
									JM <a href="https://web.stanford.edu/~jurafsky/slp3/7.pdf" target="_blank">7.5</a>
									<br />
									YG 9
									<br /><br />
									<a href="http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf" target="_blank">A Neural Probabilistic Language Model</a> (Bengio et al 2003)
									<br />
									<a href="https://www.aclweb.org/anthology/P15-1162/" target="_blank">Deep Unordered Composition Rivals Syntactic Methods for Text Classification</a> (Iyyer et al 2015)
								</td>
								<td></td>
							</tr>
							<tr>
								<td>Sep 23</td>
								<td>
									Recurrent Neural Networks
								</td>
								<td>
									JM <a href="https://web.stanford.edu/~jurafsky/slp3/9.pdf" target="_blank">9.1-9.5</a>
									<br /><br />
									<a href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" target="_blank">The Unreasonable Effectiveness of Recurrent Neural Networks</a>
								</td>
								<td></td>
							</tr>
							<tr>
								<td>Sep 25</td>
								<td>
									Vanishing gradients; RNN variants
								</td>
								<td>
									JM <a href="https://web.stanford.edu/~jurafsky/slp3/9.pdf" target="_blank">9.6</a>
									<br />
									YG 15
									<br /><br />
									<a href="http://colah.github.io/posts/2015-08-Understanding-LSTMs/" target="_blank">Understanding LSTMs</a>
									<br />
									<a href="https://www.aclweb.org/anthology/D14-1179/" target="_blank">Learning Phrase Representations using RNN Encoderâ€“Decoder for Statistical Machine Translation</a>
									<br />
									<a href="http://proceedings.mlr.press/v28/pascanu13.html" target="_blank">On the difficulty of training recurrent neural networks</a>
								</td>
								<td></td>
							</tr>
							<tr>
								<td>Sep 30</td>
								<td>
									Sequence-to-sequence; Attention
								</td>
								<td>
									JM <a href="https://web.stanford.edu/~jurafsky/slp3/10.pdf" target="_blank">10</a>
									<br /><br />
									<a href="https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks" target="_blank">Sequence to Sequence Learning with Neural Networks</a> (original seq2seq paper)
									<br />
									<a href="https://arxiv.org/pdf/1409.0473.pdf" target="_blank">Neural Machine Translation by Jointly Learning to Align and Translate</a> (original seq2seq + attention paper)
								</td>
								<td></td>
							</tr>
							<tr>
								<td>Oct 2</td>
								<td>
									Transformers 1
								</td>
								<td>
									JM <a href="https://web.stanford.edu/~jurafsky/slp3/9.pdf" target="_blank">9.7-9.9</a>
									<br /><br />
									<a href="https://arxiv.org/pdf/1706.03762.pdf" target="_blank">Attention is All You Need</a> (original Transformer paper)
									<br />
									<a href="https://nlp.seas.harvard.edu/2018/04/03/attention.html" target="_blank">The Annotated Transformer</a>
									<br />
									<a href="http://jalammar.github.io/illustrated-transformer/" target="_blank">The Illustrated Transformer</a>
								</td>
								<td></td>
							</tr>
							<tr>
								<td>Oct 7</td>
								<td>
									<a href="slides/12_transformers-2.pdf" target="_blank">Transformers 2</a>
								</td>
								<td>&quot;</td>
								<td></td>
							</tr>
							<tr>
								<td>Oct 9</td>
								<td>
									Pre-training / Fine-tuning Paradigm
								</td>
								<td>
									JM <a href="https://web.stanford.edu/~jurafsky/slp3/11.pdf" target="_blank">11</a>
									<br />
									<a href="https://dl.acm.org/doi/pdf/10.1145/3347145" target="_blank">Contextual Word Representations: Putting Words into Computers</a>
									<br />
									<a href="http://jalammar.github.io/illustrated-bert/">The Illustrated BERT, ELMo, and co. (How NLP Cracked Transfer Learning)</a>
								</td>
								<td></td>
							</tr>
							<tr>
								<td>Oct 14</td>
								<td colspan="3" align="center">Fall Break: No Class</td>
							</tr>
							<tr>
								<td>Oct 16</td>
								<td>Pre-training / fine-tuning paradigm (cont.)</td>
								<td>&quot;</td>
								<td></td>
							</tr>
							<tr>
								<td>Oct 21</td>
								<td>
									Interpretability and Analysis
								</td>
								<td>
									<a href="https://www.mitpressjournals.org/doi/full/10.1162/tacl_a_00254" target="_blank">Analysis Methods in Natural Language Processing</a>
									<br />
									<a href="https://www.mitpressjournals.org/doi/full/10.1162/tacl_a_00349" target="_blank">A Primer in BERTology</a>
								</td>
								<td></td>
							</tr>
							<tr>
								<td>Oct 23</td>
								<td>
									Multilingual NLP
								</td>
								<td>
									<a href="https://proceedings.neurips.cc/paper/2019/file/c04c19c2c2474dbf5f7ac4372c5b9af1-Paper.pdf" target="_blank">Cross-Lingual Language Model Pretraining</a>
									<br /><br />
									Optional / peruse if interested:
									<br />
									<a href="https://www.aclweb.org/anthology/2020.repl4nlp-1.16/" target="_blank">Are All Languages Created Equal in Multilingual BERT?</a>
									<br />
									<a href="https://www.aclweb.org/anthology/2020.acl-main.536/" target="_blank">Emerging Cross-lingual Structure in Pretrained Language Models</a>
									<br />
									<a href="https://arxiv.org/abs/1910.11856" target="_blank">On the Cross-lingual Transferability of Monolingual Representations</a>
									<br />
									<a href="https://arxiv.org/abs/1710.04087" target="_blank">Word Translation Without Parallel Data</a>
									<br />
									<a href="https://arxiv.org/abs/2104.07642" target="_blank">Bilingual alignment transfers to multilingual alignment for unsupervised parallel text mining</a>
								</td>
								<td></td>
							</tr>
							<tr>
								<td>Oct 28</td>
								<td>
									"Stochastic Parrots" and Criticisms of LLMs</a>
								</td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td>Oct 30</td>
								<td>
									TBA
								</td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td>Nov 4</td>
								<td>
									TBA
								</td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td>Nov 6</td>
								<td>
									TBA
								</td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td>Nov 11</td>
								<td>
									TBA
								</td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td>Nov 13</td>
								<td>
									TBA
								</td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td>Nov 18</td>
								<td>
									TBA
								</td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td>Nov 20</td>
								<td>
									TBA
								</td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td>Nov 25</td>
								<td>
									TBA
								</td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td>Nov 27</td>
								<td colspan="3" align="center">Thanksgiving Break: No Class</td>
							</tr>
							<tr>
								<td>Dec 2</td>
								<td>
									TBA
								</td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td>Dec 4</td>
								<td>
									TBA
								</td>
								<td></td>
								<td></td>
							</tr>
							<tr>
								<td>Dec 9</td>
								<td>
									Overflow / Summary / Review
								</td>
								<td></td>
								<td></td>
							</tr>
						</tbody>
					</table>
				</div>
			</div>
		</div>
	</section>

	<!-- Bootstrap core JavaScript -->
	<script src="../vendor/jquery/jquery.min.js"></script>
	<script src="../vendor/bootstrap/js/bootstrap.bundle.min.js"></script>

	<!-- Plugin JavaScript -->
	<script src="../vendor/jquery-easing/jquery.easing.min.js"></script>

	<!-- Custom JavaScript for this theme -->
	<script src="../js/scrolling-nav.js"></script>
</body>
</html>
